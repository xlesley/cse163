# -*- coding: utf-8 -*-
"""CIFAR10-classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZoIDYsiNWJVMn8_TU2qlYLKMPRyYYhDt
"""

import matplotlib.pyplot as plt
import pickle
import tensorflow as tf
from keras.utils import np_utils
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.metrics import confusion_matrix
from keras.models import Sequential
import os
import plotly.graph_objects as go

os.environ["CUDA_DEVICE_ORDER"] = "PIC_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

def get_cifar10_data():
    """
    Gets the cifar10 dataset
    """
    (x_train_origianl, y_train_original), (x_test_original, y_test_original) = tf.keras.datasets.cifar10.load_data()
    train_num=50000
    val_num=5000
    test_num=5000
    x_val = x_test_original[:val_num]
    y_val = y_test_original[:val_num]
    x_test = x_test_original[val_num:val_num+test_num]
    y_test = y_test_original[val_num:val_num+test_num]
    x_train = x_train_origianl[:train_num]
    y_train = y_train_original[:train_num]

    x_train = x_train.astype('float32')
    x_val = x_val.astype('float32')
    x_test = x_test.astype('float32')

    x_train = x_train / 255
    x_val = x_val / 255
    x_test = x_test / 255

    y_train = np_utils.to_categorical(y_train,num_classes=10)
    y_val = np_utils.to_categorical(y_val,num_classes=10)
    y_test = np_utils.to_categorical(y_test,num_classes=10)

    return x_train, y_train, x_val, y_val, x_test, y_test

x_train, y_train, x_val, y_val, x_test, y_test = get_cifar10_data()
print(x_train.shape,x_test.shape,x_val.shape)
print(y_train.shape,y_test.shape,y_val.shape)

def alexnet(input_shape=(32,32,3)):
    """
    Defines the alexnet model
    """
    model = Sequential()
    
    model.add(tf.keras.layers.Conv2D(12, (11, 11), strides=(4, 4), input_shape = (32, 32, 3), padding = 'same',
                                     activation = 'relu', kernel_initializer = 'uniform'))
    
    model.add(tf.keras.layers.MaxPooling2D(pool_size = (3, 3), strides = (2, 2)))
    model.add(tf.keras.layers.BatchNormalization())

    model.add(tf.keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding = 'same',
                                     activation = 'relu', kernel_initializer = 'uniform'))
    model.add(tf.keras.layers.MaxPooling2D(pool_size = (3, 3), strides = (2, 2)))
    model.add(tf.keras.layers.BatchNormalization())

    model.add(tf.keras.layers.Conv2D(48, (3, 3), strides=(1, 1), padding = 'same',
                                     activation = 'relu', kernel_initializer = 'uniform'))
    model.add(tf.keras.layers.Conv2D(48, (3, 3), strides=(1, 1), padding = 'same',
                                     activation = 'relu', kernel_initializer = 'uniform'))
    model.add(tf.keras.layers.Conv2D(32, (3, 3), strides=(1, 1), padding = 'same',
                                     activation = 'relu', kernel_initializer = 'uniform'))
    
    model.add(tf.keras.layers.Flatten())
    model.add(tf.keras.layers.Dense(256, activation = 'relu'))
    model.add(tf.keras.layers.Dropout(0.5))
    model.add(tf.keras.layers.Dense(128, activation = 'relu'))
    model.add(tf.keras.layers.Dropout(0.5))
    model.add(tf.keras.layers.Dense(10, activation = 'softmax'))

    print(model.summary())

    return model
    
model = alexnet()

model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])

train_history = model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs = 50, batch_size = 64, verbose = 2)

def show_train_history(train_history, train, validation):
  """
  use plotly to plot the accuracy and loss during training process
  """
  fig = go.Figure()
  fig.add_trace(go.Scatter(y=train_history.history[train], mode='lines', name='Train'))
  fig.add_trace(go.Scatter(y=train_history.history[validation], mode='lines', name='Validation'))
  fig.update_layout(title='Train History', xaxis_title='Epoch', yaxis_title=train, legend=dict(x=0, y=1))
  fig.show()

show_train_history(train_history, 'accuracy', 'val_accuracy')
show_train_history(train_history, 'loss', 'val_loss')

score = model.evaluate(x_test, y_test)
print('Test loss: ', score[0])
print('Test accuracy: ', score[1])

predictions = model.predict(x_test)
predictions = np.argmax(predictions, axis = 1)
print('The predictions for the first 20 images: ', predictions[:20])

def cifar10_visualize_multiple_predict(start, end, length, width):
  """
  Visualizes the prediction in images
  """
  for i in range(start, end):
      plt.subplot(length, width, 1 + i)
      plt.imshow(x_test_original[i], cmap = plt.get_cmap('gray'))
      title_true = 'true= ' + str(y_test_original[i])
      title_prediction = '\nprediction = ' + str(predictions[i])
      title = title_true + title_prediction
      plt.title(title)
      plt.xticks([])
      plt.yticks([])
  plt.tight_layout(pad=0.4, w_pad=4, h_pad=0.1)
  plt.show()

(x_train_original, y_train_original), (x_test_original, y_test_original) = tf.keras.datasets.cifar10.load_data()
cifar10_visualize_multiple_predict(0, 20, 4, 5)